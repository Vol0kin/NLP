{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fe7e02a-c395-4852-9d99-e784312574a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d81673c9-4c59-4cd7-a3c8-880202685d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,sys,inspect\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b88485f9-8a10-45b0-8b4c-c8db43d01454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The skseq library must be previously installed. Here we assume it is in '../skseq'\n",
    "sys.path.insert(0,'../') \n",
    "import skseq\n",
    "\n",
    "from skseq.sequences.sequence import Sequence\n",
    "from skseq.sequences.sequence_list import SequenceList\n",
    "from skseq.sequences.label_dictionary import LabelDictionary\n",
    "import skseq.sequences.structured_perceptron as spc\n",
    "import skseq.sequences.extended_feature as exfc\n",
    "\n",
    "from utils.utils import build_sequence_list, evaluate_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13770872-86a2-4eba-8544-5ee3b517bf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train_data_ner.csv')\n",
    "tag_dict = LabelDictionary(label_names=set(df_train.tags))\n",
    "\n",
    "# Generate dictionary of words for training dataset\n",
    "word_dict_train = LabelDictionary(label_names=set(df_train.words))\n",
    "\n",
    "# Build sequence list\n",
    "train_seq = build_sequence_list(df_train[df_train.sentence_id.isin(range(20))], word_dict_train, tag_dict)\n",
    "\n",
    "# Define features\n",
    "# feature_mapper = skseq.sequences.id_feature.IDFeatures(train_seq)\n",
    "\n",
    "feature_mapper = exfc.ExtendedFeatures(train_seq) \n",
    "feature_mapper.build_features()\n",
    "\n",
    "inv_feature_dict = {word: pos for pos, word in feature_mapper.feature_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec429be8-dd8c-4582-a804-91c5911a9942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5992/4 23033/4 31839/4 27200/4 1785/4 2978/4 25132/4 \n",
      "Some/O 1,27,000/O people/O are/O known/O dead/O ./O \n"
     ]
    }
   ],
   "source": [
    "id_seq = 6\n",
    "print(train_seq[id_seq])\n",
    "print(train_seq[id_seq].to_words(train_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "defb3313-5438-4ec2-b027-8dfb1ffd6fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0]],\n",
       " [[3], [3], [3], [3], [3], [3]],\n",
       " [[28]],\n",
       " [[132], [133], [106], [47], [134], [135], [27]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without extendend features\n",
    "feature_mapper.get_sequence_features(train_seq[id_seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95a59f4d-d13f-48cd-a104-b6ab7bd2df5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0]],\n",
       " [[4], [4], [4], [4], [4], [4]],\n",
       " [[31]],\n",
       " [[146, 2], [147], [120], [52], [148], [149], [30]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with extended features\n",
    "feature_mapper.get_sequence_features(train_seq[id_seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b364aee-3360-4ead-8638-f540ad1e1c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'init_caps::O'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_feature_dict[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1fd9fe-0229-459a-b607-a8b39a98df5e",
   "metadata": {},
   "source": [
    "Other features are identified by starting with **uppercased**, **suffix**, **preffix** etc...\n",
    "\n",
    "- **uppercased:** when they contain the current word with an uppercased letter\n",
    "    - Example: **``uppercased::noun``** is a feature stating that current word is uppercased and the current tag is a noun.\n",
    "\n",
    "- **prefix:** when the current word contains a certain prefix.\n",
    "    - Example: prefix:Eli::noun\n",
    "\n",
    "- **suffix:** when the current word contains a certain suffix.\n",
    "    - Example: suffix:ing:verb\n",
    "    \n",
    "| Conditions to be met for some of the most typical POS features     |    Name      |\n",
    "| ----------------                                | ----------------    |\n",
    "| $x_i=w_j ,\\,\\,  w_j \\text{ is uppercased } ,\\,\\,  y_i=c_k$                 | Upper case features|\n",
    "| $x_i=w_j ,\\,\\,  w_j \\text{ contains digit} ,\\,\\,  y_i=c_k$                 | Digit features|\n",
    "| $x_i=w_j ,\\,\\,  w_j \\text{ contains hyphen} ,\\,\\,  y_i=c_k$                 | Hyphen features|\n",
    "| $x_i=w_j ,\\,\\,  w_j[0:i] \\in P_{set}  \\forall i \\in \\{1,2,3\\}  ,\\,\\,  y_i=c_k$                 | Prefix features|\n",
    "| $x_i=w_j ,\\,\\,  w_j[-i] \\in S_{set}  \\forall i \\in \\{1,2,3\\}  ,\\,\\,  y_i=c_k$                 | Suffix features|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39300262-beba-4ef0-896e-d52af69d8e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geo: country\n",
    "# Tim: time (day, month, year, recent, today...)\n",
    "# Org: organization (US, United states, al-Qaida)\n",
    "# Per: Person (Mr, Ms, prime minister, alba)\n",
    "# Art: facebook, english, ... ??\n",
    "# GPE: nationality\n",
    "# EVE: event (olympic games, ramadan...)\n",
    "# NAT: natural event (ebola, hurricane, aids, katrina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ca82f7-c442-4887-bc45-c49aea2df1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train.tags == 'B-tim','words'].value_counts().head(150).tail(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45daeb70-82dd-4af8-b51a-aa8dd502ffa2",
   "metadata": {},
   "source": [
    "<b> HMM-like emission features </b>\n",
    "* X HMM-like emission\n",
    "\n",
    "<b> Small features </b>\n",
    "* X Initialism\n",
    "* X Is digit\n",
    "* X 1 digit\n",
    "* X 2 digits\n",
    "* X 4 digits\n",
    "* X digits + s\n",
    "* X digits + st\n",
    "* X digits + th\n",
    "* X Is floating point\n",
    "* X Word contains dot\n",
    "* X Word contains hypend\n",
    "* X Word contains apostrophe\n",
    "* X First letter is uppercase\n",
    "* X All letters are uppercase\n",
    "* X Mixed case.\n",
    "* X word length (1-10,10-15,>15)\n",
    "* X Word between quotes\n",
    "* Change y to lowercase once uppercase info is stored in a variable?\n",
    "\n",
    "<b> Local knowledge </b>\n",
    "* wi, wi+1, wi-1\n",
    "* more extensive local kwnoledge for capitalized words ??\n",
    "* suffixes \n",
    "* prefixes\n",
    "* lemmatizers\n",
    "* stemmers\n",
    "\n",
    "<b> POS tags </b>\n",
    "\n",
    "<b> Words clustering </b>\n",
    "* with word2vec\n",
    "\n",
    "<b> Gazetteer </b>\n",
    "* wikipedia articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe38cfe-d0ce-4ab1-9677-805da5712bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_emission_features(self, sequence, pos, y, features):\n",
    "    x = sequence.x[pos]\n",
    "    \n",
    "    # Words surrounding x\n",
    "    #if pos != 0:\n",
    "    #    x_pre = sequence.x[pos-1]\n",
    "    #if pos != len(sequence):\n",
    "    #    x_post = sequence.x[pos+1]\n",
    "        \n",
    "    # Get tag name from ID.\n",
    "    y_name = self.dataset.y_dict.get_label_name(y)\n",
    "    # Get word name from ID.\n",
    "    if isinstance(x, str):\n",
    "        x_name = x\n",
    "    else:\n",
    "        x_name = self.dataset.x_dict.get_label_name(x)\n",
    "        #x_pre = self.dataset.x_dict.get_label_name(x_pre)\n",
    "        #x_post = self.dataset.x_dict.get_label_name(x_post)\n",
    "        \n",
    "    word = str(x_name)\n",
    "    \n",
    "    # HMM-LIKE EMISSION FEATURES\n",
    "    feat_name = f\"id:{word}::{y_name}\" # Generate feature name.\n",
    "    feat_id = self.add_feature(feat_name) # Get feature ID from name.\n",
    "    # Append feature.\n",
    "    if feat_id != -1:\n",
    "        features.append(feat_id)\n",
    "    \n",
    "    # WORD STRUCTURE FEATURES\n",
    "    # Feature: first letter is capitalized\n",
    "    if word.istitle():\n",
    "        feat_name = f\"uppercased:first::{y_name}\"\n",
    "        feat_id = self.add_feature(feat_name) \n",
    "\n",
    "        if feat_id != -1:\n",
    "            features.append(feat_id)\n",
    "\n",
    "    # Feature: all letters are uppercase\n",
    "    if word.isupper():\n",
    "        feat_name = f\"uppercased:all::{y_name}\"\n",
    "        feat_id = self.add_feature(feat_name)\n",
    "\n",
    "        if feat_id != -1:\n",
    "            features.append(feat_id)\n",
    "\n",
    "    # Feature: is digit\n",
    "    if str.isdigit(word):\n",
    "        feat_name = f\"digit::{y_name}\"\n",
    "        feat_id = self.add_feature(feat_name)\n",
    "\n",
    "        if feat_id != -1:\n",
    "            features.append(feat_id)\n",
    "        \n",
    "        # Features: digits of length 1, 2 or 4 \n",
    "        for i in [1, 2, 4]:\n",
    "            if len(word) == i:\n",
    "                feat_name = f\"digit:{str(i)}::{y_name}\"\n",
    "                feat_id = self.add_feature(feat_name)\n",
    "                if feat_id != -1:\n",
    "                    features.append(feat_id)                  \n",
    "    \n",
    "    # Feature: is floating point number\n",
    "    try:\n",
    "        float(word)\n",
    "\n",
    "        feat_name = f\"float::{y_name}\"\n",
    "        feat_id = self.add_feature(feat_name)\n",
    "\n",
    "        if feat_id != -1:\n",
    "            features.append(feat_id)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "\n",
    "    # Feature: word contains dot\n",
    "    if len(word) > 1 and '.' in word:\n",
    "        feat_name = f\"has_dot::{y_name}\"\n",
    "        feat_id = self.add_feature(feat_name)\n",
    "\n",
    "        if feat_id != -1:\n",
    "            features.append(feat_id)\n",
    "\n",
    "    # Features: word length\n",
    "    for i in range(1, 11):\n",
    "        if len(word) == i:\n",
    "            feat_name = f\"length:{str(i)}::{y_name}\"\n",
    "            feat_id = self.add_feature(feat_name)\n",
    "\n",
    "            if feat_id != -1:\n",
    "                features.append(feat_id)\n",
    "                \n",
    "    if len(word) > 10 & len(word) <= 15:\n",
    "        feat_name = f\"length:10-15::{y_name}\"\n",
    "        feat_id = self.add_feature(feat_name)\n",
    "        if feat_id != -1:\n",
    "            features.append(feat_id)\n",
    "            \n",
    "    if len(word) > 15:\n",
    "        feat_name = f\"length:gt15::{y_name}\"\n",
    "        feat_id = self.add_feature(feat_name)\n",
    "        if feat_id != -1:\n",
    "            features.append(feat_id) \n",
    "            \n",
    "    # Features: detect several patterns\n",
    "    patterns = [r\"(\\w\\.){2,}\", r\"\\d+s\", r\"\\d+st\", r\"\\d+nd\", r\"\\d+rd\", r\"\\d+th\", r\"\\-\", r\"(^\\'\\w+\\'$)|(^\\\"\\w+\\\"$)\", \"([A-Z]+[a-z]+)|([a-z]+[A-Z]+)\", r\"\\'\"]\n",
    "    labels = [\"initialism\",\"digit:s\",\"digit:st\",\"digit:nd\",\"digit:rd\",\"digit:th\",\"hypend\",\"quote\",\"uppercased:mixed\",\"apostrophe\"]\n",
    "    for pattern, label in zip(patterns, labels):\n",
    "        regx = re.compile(pattern)\n",
    "\n",
    "        if bool(regx.match(word)):\n",
    "            print(f\"{label}::{y_name}\")\n",
    "            \n",
    "    # CONTEXTUAL FEATURES        \n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "* wi, wi+1, wi-1\n",
    "* more extensive local kwnoledge for capitalized words ??\n",
    "* suffixes \n",
    "* prefixes\n",
    "* lemmatizers\n",
    "* stemmers    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
