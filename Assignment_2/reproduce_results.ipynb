{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T14:44:48.896179Z",
     "start_time": "2020-05-12T14:44:48.649812Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T14:44:49.049052Z",
     "start_time": "2020-05-12T14:44:48.998738Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,sys,inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T14:44:49.173923Z",
     "start_time": "2020-05-12T14:44:49.148685Z"
    }
   },
   "outputs": [],
   "source": [
    "# The skseq library must be previously installed. Here we assume it is in '../skseq'\n",
    "sys.path.insert(0,'../') \n",
    "import skseq\n",
    "\n",
    "from skseq.sequences.sequence import Sequence\n",
    "from skseq.sequences.sequence_list import SequenceList\n",
    "\n",
    "from skseq.sequences.label_dictionary import LabelDictionary\n",
    "\n",
    "import skseq.sequences.structured_perceptron as spc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import build_sequence_list, evaluate_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(839149, 3)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/train_data_ner.csv')\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(837339, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>words</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Iranian</td>\n",
       "      <td>B-gpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>officials</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>say</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>they</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>expect</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id      words   tags\n",
       "0            1    Iranian  B-gpe\n",
       "1            1  officials      O\n",
       "2            1        say      O\n",
       "3            1       they      O\n",
       "4            1     expect      O"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('data/test_data_ner.csv')\n",
    "print(df_test.shape)\n",
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct tags: 17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'I-nat': 0,\n",
       " 'B-art': 1,\n",
       " 'B-nat': 2,\n",
       " 'I-geo': 3,\n",
       " 'I-per': 4,\n",
       " 'I-gpe': 5,\n",
       " 'I-org': 6,\n",
       " 'B-gpe': 7,\n",
       " 'O': 8,\n",
       " 'I-art': 9,\n",
       " 'I-eve': 10,\n",
       " 'B-per': 11,\n",
       " 'I-tim': 12,\n",
       " 'B-org': 13,\n",
       " 'B-eve': 14,\n",
       " 'B-tim': 15,\n",
       " 'B-geo': 16}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We assume that the training data includes all possible tags that may exist (17 tags)\n",
    "\n",
    "tag_dict = LabelDictionary(label_names=set(df_train.tags))\n",
    "print('Number of distinct tags:', len(tag_dict))\n",
    "tag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct words in train set:  31979\n"
     ]
    }
   ],
   "source": [
    "# Generate dictionary of words for training dataset\n",
    "word_dict_train = LabelDictionary(label_names=set(df_train.words))\n",
    "print('Number of distinct words in train set: ', len(word_dict_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct words in test set:  43955\n"
     ]
    }
   ],
   "source": [
    "# Generate dictionary of words for test dataset\n",
    "word_dict_test = LabelDictionary(label_names=set(df_test.words))\n",
    "print('Number of distinct words in test set: ', len(word_dict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build train_seq and test_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.47 s, sys: 17.6 ms, total: 1.49 s\n",
      "Wall time: 1.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Build sequence_list object with train data\n",
    "\n",
    "train_seq = build_sequence_list(df_train, word_dict_train, tag_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.35 s, sys: 20.7 ms, total: 1.37 s\n",
      "Wall time: 1.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Build sequence_list object with test data\n",
    "\n",
    "test_seq = build_sequence_list(df_test, word_dict_test, tag_dict, use_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T14:45:00.787327Z",
     "start_time": "2020-05-12T14:45:00.771264Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38366, 38367)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of sequences in train and test\n",
    "len(train_seq), len(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T14:45:01.866931Z",
     "start_time": "2020-05-12T14:45:01.851802Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31979, 43955)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocabulary size\n",
    "len(train_seq.x_dict), len(test_seq.x_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19374/8 2285/8 21686/8 12468/8 25447/8 18898/8 17647/16 25471/8 10856/8 9017/8 2890/8 8141/8 20800/16 5877/8 856/8 9017/8 3174/8 2285/8 3422/7 25366/8 8375/8 6862/8 15822/8 2558/8 "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thousands/O of/O demonstrators/O have/O marched/O through/O London/B-geo to/O protest/O the/O war/O in/O Iraq/B-geo and/O demand/O the/O withdrawal/O of/O British/B-gpe troops/O from/O that/O country/O ./O '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq[0].to_words(sequence_list=train_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get feature mapper (from training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_mapper = skseq.sequences.id_feature.IDFeatures(train_seq)\n",
    "feature_mapper.build_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clusters_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequences\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextended_feature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExtendedFeatures\n\u001b[0;32m----> 2\u001b[0m extended_feature_mapper \u001b[38;5;241m=\u001b[39m ExtendedFeatures(train_seq, \u001b[43mclusters_dict\u001b[49m, \u001b[38;5;28mlen\u001b[39m(k_means\u001b[38;5;241m.\u001b[39mlabels_))\n\u001b[1;32m      3\u001b[0m extended_feature_mapper\u001b[38;5;241m.\u001b[39mbuild_features()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clusters_dict' is not defined"
     ]
    }
   ],
   "source": [
    "from skseq.sequences.extended_feature import ExtendedFeatures\n",
    "clusters_dict = 'fitted_models/clusters_dict.joblib')\n",
    "extended_feature_mapper = ExtendedFeatures(train_seq, clusters_dict, 100)\n",
    "extended_feature_mapper.build_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spc.StructuredPerceptron(word_dict_train, tag_dict, feature_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.load_model(dir=\"fitted_models/model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_features = spc.StructuredPerceptron(word_dict_train, tag_dict, feature_mapper)\n",
    "sp_features.save_model(\"fitted_models/model_features_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/Documents/MasterDS/NLP/NLP/Assignment_2/skseq/sequences/sequence_classifier.py:147\u001b[0m, in \u001b[0;36mSequenceClassifier.viterbi_decode_corpus\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    145\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sequence \u001b[38;5;129;01min\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mseq_list:\n\u001b[0;32m--> 147\u001b[0m     predicted_sequence, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mviterbi_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(predicted_sequence)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[0;32m~/Documents/MasterDS/NLP/NLP/Assignment_2/skseq/sequences/sequence_classifier.py:133\u001b[0m, in \u001b[0;36mSequenceClassifier.viterbi_decode\u001b[0;34m(self, sequence)\u001b[0m\n\u001b[1;32m    129\u001b[0m initial_scores, transition_scores, final_scores, emission_scores \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_scores(sequence)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Run the forward algorithm.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m best_states, total_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_viterbi\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mtransition_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mfinal_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43memission_scores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m predicted_sequence \u001b[38;5;241m=\u001b[39m sequence\u001b[38;5;241m.\u001b[39mcopy_sequence()\n\u001b[1;32m    139\u001b[0m predicted_sequence\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m best_states\n",
      "File \u001b[0;32m~/Documents/MasterDS/NLP/NLP/Assignment_2/skseq/sequences/sequence_classification_decoder.py:109\u001b[0m, in \u001b[0;36mSequenceClassificationDecoder.run_viterbi\u001b[0;34m(self, initial_scores, transition_scores, final_scores, emission_scores)\u001b[0m\n\u001b[1;32m    105\u001b[0m     viterbi_scores[pos] \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    106\u001b[0m         np\u001b[38;5;241m.\u001b[39mmax(viterbi_scores[pos\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m transition_scores[pos\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    107\u001b[0m     viterbi_scores[pos] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m emission_scores[pos]\n\u001b[1;32m    108\u001b[0m     viterbi_paths[pos] \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m--> 109\u001b[0m         \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mviterbi_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpos\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtransition_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpos\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Termination.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m best_score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(viterbi_scores[length\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;241m+\u001b[39m final_scores)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:1127\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_argmax_dispatcher\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   1124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, out)\n\u001b[0;32m-> 1127\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_argmax_dispatcher)\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21margmax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;124;03m    Returns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;124;03m    (2, 1, 4)\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m     kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred_train = sp.viterbi_decode_corpus(train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 13s, sys: 456 ms, total: 1min 13s\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred_test = sp.viterbi_decode_corpus(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate train dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m O_value \u001b[38;5;241m=\u001b[39m train_seq\u001b[38;5;241m.\u001b[39my_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# code of 'O' value, to be ignored\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m eval_train \u001b[38;5;241m=\u001b[39m evaluate_corpus(train_seq\u001b[38;5;241m.\u001b[39mseq_list, \u001b[43mpred_train\u001b[49m, train_seq\u001b[38;5;241m.\u001b[39my_dict, ignore_tag_code\u001b[38;5;241m=\u001b[39mO_value)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate train dataset\n",
    "O_value = train_seq.y_dict['O']  # code of 'O' value, to be ignored\n",
    "eval_train = evaluate_corpus(train_seq.seq_list, pred_train, train_seq.y_dict, ignore_tag_code=O_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate test dataset\n",
    "eval_test = evaluate_corpus(test_seq.seq_list, pred_test, test_seq.y_dict, ignore_tag_code=O_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the \"tiny test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentence(p):\n",
    "    # Create a seq object with empty tags\n",
    "    new_seq = skseq.sequences.sequence.Sequence(x=p.split(), y=[int(0) for w in p.split()])\n",
    "    return sp.viterbi_decode(new_seq)[0].to_words(train_seq, only_tag_translation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The/O programmers/O from/O Barcelona/B-geo might/O write/O a/O sentence/O without/O a/O spell/B-art checker./I-art '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence(\"The programmers from Barcelona might write a sentence without a spell checker.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The/O programmers/O from/O Barchelona/O cannot/O write/O a/O sentence/O without/O a/O spell/B-art checker./I-art '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence(\"The programmers from Barchelona cannot write a sentence without a spell checker.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jack/B-per London/B-geo went/O to/O Parris./O '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence(\"Jack London went to Parris.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jack/B-per London/B-geo went/O to/O Paris./O '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence(\"Jack London went to Paris.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bill/B-per gates/O and/O Steve/B-per jobs/O never/O though/O Microsoft/B-org would/O become/O such/O a/O big/O company./O '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence(\"Bill gates and Steve jobs never though Microsoft would become such a big company.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bill/B-per Gates/I-per and/O Steve/B-per Jobs/I-per never/O though/O Microsof/O would/O become/O such/O a/O big/O company./O '"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence(\"Bill Gates and Steve Jobs never though Microsof would become such a big company.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The/O president/O of/O U.S.A/O though/O they/O could/O win/O the/O war./O '"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence(\"The president of U.S.A though they could win the war.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The/O president/O of/O the/O United/B-geo States/I-geo of/O America/B-geo though/O they/O could/O win/O the/O war./O '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence(\"The president of the United States of America though they could win the war.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The/O king/O of/O Saudi/B-geo Arabia/I-geo wanted/O total/O control./O '"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence(\"The king of Saudi Arabia wanted total control.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Robin/O does/O not/O want/O to/O go/O to/O Saudi/B-art Arabia./I-art '"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence(\"Robin does not want to go to Saudi Arabia.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apple/O is/O a/O great/O company./O '"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence(\"Apple is a great company.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I/O really/O love/O apples/O and/O oranges./O '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence(\"I really love apples and oranges.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alice/O and/O Henry/B-per went/O to/O the/O Microsoft/B-org store/O to/O buy/O a/O new/O computer/O during/O their/O trip/O to/O New/B-org York./I-org '"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence(\"Alice and Henry went to the Microsoft store to buy a new computer during their trip to New York.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
